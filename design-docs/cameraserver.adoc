= CameraServer Library
:toc:
:toc-placement: preamble
:sectanchors:
:source-highlighter: pygments
:pygments-style: colorful

The purpose of the camera server library is to provide a standardized,
high performance, robust, and reliable method for robot code to access
multiple cameras (either USB or IP), configure the camera settings,
provide images to robot code, and stream either raw camera images or
robot code processed images as M-JPEG over HTTP stream(s) to dashboard
applications.

[[references]]
== References

[[rfc2435,RFC2435]]
* RFC 2435, RTP Payload Format for JPEG-compressed Video,
https://tools.ietf.org/html/rfc2435

[[rfc3550,RFC3550]]
* RFC 3550, RTP: A Transport Protocol for Real-Time Applications,
https://tools.ietf.org/html/rfc3550

[[rfc2326,RFC2326]]
* RFC 2326, Real Time Streaming Protocol (RTSP),
https://tools.ietf.org/html/rfc2326

[[MJPEG-HTTP]]
* M-JPEG over HTTP, http://en.wikipedia.org/wiki/Motion_JPEG

[[architecture]]
== Architecture

The basic architecture of the CameraServer library is similar to that
of MJPGStreamer, with functionality split between inputs and outputs.
There can be multiple inputs and multiple outputs created and
operating simultaneously.

* Inputs receive individual frames (such as provided by a USB camera)
and fire an event when a new frame is available.  If no outputs are
listening to a particular input, the library may pause or disconnect
from a input to save processor and I/O resources.  The library
autonomously handles camera disconnects/reconnects by simply pausing
and resuming the image stream.

* Outputs listen to a particular input's event, grab the latest
image, and forward it to its destination in the appropriate format.
Similarly to inputs, if a particular output is inactive (e.g. no
client is connected to a configured M-JPEG over HTTP server), the
library will disable parts of its processing to save processor
resources.

* In addition, user code (such as that used in a FRC robot program)
can act as either a input (providing processed frames) or as an
output (receiving a frame from a camera).

The library distinguishes "frames" from "images" as some types of
cameras (such as depth cameras or binocular vision cameras) can
provide multiple images per frame (the library refers to these as
numbered "channels").  Output modules are only capable of sending
single images, so it's necessary to configure an output module to
select which channel of the input should be used for the output
stream.

The library is designed to run as separate threads within the user
process.  This is primarily done for efficiency reasons in the case of
user image processing, but also ensures a clean, consistent runtime
environment each time the user program is run.

[[implementation]]
== Implementation

For performance reasons, the library is implemented in {cpp} and
provides both a C and {cpp} API.  A Java API is provided via JNI.

=== Dependencies

* OpenCV
* WPILib Utility Library (TBR: or NTcore)

=== Portability

While the primary target platform is Linux (both embedded and
desktop), the library also provides Windows support to enable use
cases such as off-robot simulation or image processing testing.

[[api]]
== API

The C API prefixes all names with `CS_`.

The C API uses an opaque handle based approach.  While handles do not
have unique types (all handles are `typedef int` in the API), they are
globally unique in the library, and the library can detect bugs such
as interchanging of a input and an output handle.

Handle types:

* CS_Input

* CS_Output

* CS_InputListener

* CS_OutputListener

The API for cameras is based on that provided by OpenCV.  This is
intentional, as on Linux systems the functions will largely be
passthrough (at least for USB cameras).

=== Input Management

==== CreateUSBCameraDev

[source,c]
CS_Input CS_CreateUSBCameraDev(int dev);

Connects to a USB camera based on device number (e.g. on Linux,
`/dev/videoN`).

==== CreateUSBCameraPath

[source,c]
CS_Input CS_CreateUSBCameraPath(const char* path);

Connects to a USB camera at the specified path.  Using this can
resolve ambiguity when using multiple USB cameras.

On Linux, this can either be `/dev/videoN` (note: this does not solve
the ambiguity problem) or something that symlinks to it such as
`/dev/v4l/by-path/pci-...`.

TBD: How to do something similar on Windows.

==== CreateHTTPCamera

[source,c]
CS_Input CS_CreateHTTPCamera(const char* url);

Connects to a M-JPEG over HTTP server (as commonly provided by IP
cameras).  URL should be of the form
`"http://user:pass@server:port/path/to/stream"`.

==== CreateUserInput

[source,c]
CS_Input CS_CreateUserInput(int nChannels);

==== DestroyInput

[source,c]
void CS_DestroyInput(CS_Input input);

==== EnumerateInputs

==== AddInputListener

[source,c]
CS_InputListener CS_AddInputListener(void (*callback) (CS_Input input, const CS_InputInfo* info, int event), int eventMask);

Notifies a callback function when an input is created, destroyed, or
changes state.  The eventMask is a bitmask which specifies what events
should cause a callback to occur.

[cols="1,3"]
|===
|Event |Description

|Create
|New input created

|Destroy
|Input destroyed

|Connected
|Input connected (e.g. camera successfully connected)

|Disconnected
|Input disconnected (lost IP connection, USB camera disconnected)
|===


==== RemoveInputListener

[source,c]
void CS_RemoveInputListener(CS_InputListener listener);

=== Output Management

==== CreateHTTPOutput

[source,c]
CS_Output CS_CreateHTTPOutput(const char* listenAddress, int port);

Creates a M-JPEG over HTTP server at the specified port.  The server
allows multiple clients to connect to the port (this will effectively
act as multiple virtual outputs listening to the same input that is
configured for this output).

==== CreateRTSPOutput

[source,c]
CS_Output CS_CreateRTSPOutput(const char* listenAddress, int port);

Creates a M-JPEG over RTP server at the specified port.  The RTSP
server will be at the specified port, but data will be sent via M-JPEG
over UDP in accordance with <<rfc2435>>.

==== DestroyOutput

[source,c]
void CS_DestroyOutput(CS_Output output);

==== EnumerateOutputs

==== AddOutputListener

==== RemoveOutputListener

=== User Input Functions

These functions are only valid for use with inputs created with
CreateUserInput().

==== PutImage

[source,c]
CS_PutImage(CS_Input input, int channel, CvMat* image);

Puts an OpenCV image as the latest image for an user input and
channel.  This does *not* notify outputs that a new image is
available; NotifyFrame() must be called to do that.

==== NotifyFrame

[source,c]
void CS_NotifyFrame(CS_Input input);

Notifies outputs that a user input has a new frame available.

=== Input Functions

==== WaitForFrame

[source,c]
long CS_WaitForFrame(CS_Input input);  // returns frame timestamp

Polled interface to wait for a new frame from an input (usually a
camera).

This function is blocking and does not return until a new frame has
been received or the input has been destroyed by another thread or
due to program shutdown (in which case 0 is returned).  In particular,
this function does *not* return simply due to a camera disconnect (as
this may be a temporary condition).

==== GetImage

[source,c]
CS_ErrorCode CS_GetImage(CS_Input input, int channel, CvMat* image, long* timestamp);

Gets the latest image from an input (usually a camera).  The image is
provided as a OpenCV image in whatever raster format is provided by
the camera.

The frame timstamp is also provided to detect if a new frame has been
received.  In general, code should call `WaitForFrame()` before using
this function, as this function is expensive to execute.

==== GetInputInfo

[source,c]
CS_InputInfo* CS_GetInputInfo(CS_Input input);

Gets information about the input (see <<struct-input-info>>).

[[struct-input-info]]
===== InputInfo

[cols="1,3"]
|===
|Field Name |Field Type

|Id
|Integer, Input Id (as returned by CreateX)

|Description
|String, short description of input (type-dependent)

|Connected
|Boolean, whether the input is currently connected to the device.  Always
true for UserInput inputs.

|Last Frame Time
|Timestamp of last frame generated by this input.  If no outputs are
connected, may not be updated.

|# Channels
|Number of channels the input provides
|===

==== GetCameraParameters

==== SetCameraParameters

=== Output Functions

==== SetOutputInput

[source,c]
CS_ErrorCode CS_SetOutputInput(CS_Output output, CS_Input input, int channel);

Configures the output to get images from the specified input and
channel.

==== GetOutputInfo

== Examples

=== Stream a single USB camera as a HTTP M-JPEG stream

This simple example provides a M-JPEG stream for a single USB camera
on port 5800.  The streaming server will run in the background until
the program terminates.  This example can be simply extended for
multiple USB cameras (just copy and paste with different device
numbers and port numbers).

[source,c]
----
CS_Input cameraInput = CS_CreateUSBCameraDev(0);
CS_Output httpOutput = CS_CreateHTTPOutput("", 5800);
CS_SetOutputInput(httpOutput, cameraInput, 0);
----

=== Process USB camera images and stream both unprocessed and processed M-JPEG

The below example code provides the raw USB camera stream on port
5800, but also processes the image and provides the processed image on
port 5801.

[source,cpp]
----
// In separate thread (due to blocking call to WaitForFrame)

// Create inputs
CS_Input cameraInput = CS_CreateUSBCameraDev(0);
CS_Input processedInput = CS_CreateUserInput(1);

// Create outputs and connect them to desired inputs
CS_Output unprocessedOutput = CS_CreateHTTPOutput("", 5800);
CS_Output processedOutput = CS_CreateHTTPOutput("", 5801);
CS_SetOutputInput(unprocessedOutput, cameraInput, 0);
CS_SetOutputInput(processedOutput, processedInput, 0);

for (;;) {
  // Wait for a new frame from the camera
  long ts = CS_WaitForFrame(cameraInput);
  if (ts == 0) break;  // program ending...

  // Get OpenCV image from camera
  cv::Mat image;
  long ts2;
  CS_ErrorCode err = CS_GetImage(cameraInput, 0, &image, &ts2);
  if (err != CS_OK) continue;

  // ... process image using OpenCV ...

  // Provide processed image
  CS_PutImage(processedInput, 0, image);
  CS_NotifyFrame(processedInput);
}
----

=== Process binocular camera images

[source,cpp]
----
// In separate thread (due to blocking call to WaitForFrame)

CS_Input cameraInput = CS_CreateUSBCameraDev(0);

for (;;) {
  // Wait for a new frame from the camera
  long ts = CS_WaitForFrame(cameraInput);
  if (ts == 0) break;  // program ending...

  // Get OpenCV images from camera
  cv::Mat image0;
  long ts0;
  CS_ErrorCode err = CS_GetImage(cameraInput, 0, &image, &ts0);
  if (err != CS_OK) continue;

  cv::Mat image1;
  long ts1;
  CS_ErrorCode err = CS_GetImage(cameraInput, 1, &image, &ts1);
  if (err != CS_OK) continue;

  if (ts != ts0 || ts != ts1) {
    // Received split image (processor too slow?)
    continue;
  }

  // ... process images using OpenCV ...
}
----

== TODO / Discussion Topics

* Supporting things like Kinect will add major dependencies (like
OpenNI).  Plugins seem like the right way to handle this but that also
adds significant complexity.

* Error reporting/handling?

* Should exposing things like camera settings to NetworkTables be done
here or at the next higher level of libraries?

